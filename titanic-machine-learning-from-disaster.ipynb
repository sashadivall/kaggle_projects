{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-08T18:26:37.594002Z","iopub.execute_input":"2024-07-08T18:26:37.594538Z","iopub.status.idle":"2024-07-08T18:26:37.610427Z","shell.execute_reply.started":"2024-07-08T18:26:37.594497Z","shell.execute_reply":"2024-07-08T18:26:37.609219Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-07-08T18:43:50.075641Z","iopub.execute_input":"2024-07-08T18:43:50.076123Z","iopub.status.idle":"2024-07-08T18:43:50.100507Z","shell.execute_reply.started":"2024-07-08T18:43:50.076087Z","shell.execute_reply":"2024-07-08T18:43:50.099093Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T18:43:50.820175Z","iopub.execute_input":"2024-07-08T18:43:50.821125Z","iopub.status.idle":"2024-07-08T18:43:50.836282Z","shell.execute_reply.started":"2024-07-08T18:43:50.821091Z","shell.execute_reply":"2024-07-08T18:43:50.835115Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Import dependencies\nimport tensorflow as tf\nimport tensorflow_decision_forests as tfdf\n\nprint(f\"Found TF-DF {tfdf.__version__}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-08T18:43:54.620067Z","iopub.execute_input":"2024-07-08T18:43:54.620471Z","iopub.status.idle":"2024-07-08T18:43:54.626484Z","shell.execute_reply.started":"2024-07-08T18:43:54.620440Z","shell.execute_reply":"2024-07-08T18:43:54.625319Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Found TF-DF 1.8.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Prepare Dataset\nWe will apply the following transformations on the dataset.\n* Tokenize the names. For example, \"Brauind, Mr. Owen Harris\" will become [\"Braund\", \"Mr.\", \"Owen\", \"Harris\"].\n* Extract any prefix in the ticket. For example, ticket \"STON/O2.3101282\" will become \"STON/O2.\" and 3101282.","metadata":{}},{"cell_type":"code","source":"def preprocess(df):\n    df = df.copy()\n    \n    def normalize_name(x):\n        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n\n    def ticket_number(x):\n        return x.split(\" \")[-1]\n    \n    def ticket_item(x):\n        items = x.split(\" \")\n        if len(items) == 1:\n            return \"NONE\"\n        return \"_\".join(items[0:-1])\n    \n    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n    df[\"Ticket_Number\"] = df[\"Ticket\"].apply(ticket_number)\n    df[\"Ticket_Item\"] = df[\"Ticket\"].apply(ticket_item)\n    return df\n\npreprocessed_train_data = preprocess(train_data)\npreprocessed_test_data = preprocess(test_data)\n\npreprocessed_train_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T18:43:57.590996Z","iopub.execute_input":"2024-07-08T18:43:57.591805Z","iopub.status.idle":"2024-07-08T18:43:57.623261Z","shell.execute_reply.started":"2024-07-08T18:43:57.591768Z","shell.execute_reply":"2024-07-08T18:43:57.621831Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                              Name     Sex   Age  SibSp  \\\n0                            Braund Mr Owen Harris    male  22.0      1   \n1  Cumings Mrs John Bradley Florence Briggs Thayer  female  38.0      1   \n2                             Heikkinen Miss Laina  female  26.0      0   \n3         Futrelle Mrs Jacques Heath Lily May Peel  female  35.0      1   \n4                           Allen Mr William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked Ticket_Number Ticket_Item  \n0      0         A/5 21171   7.2500   NaN        S         21171         A/5  \n1      0          PC 17599  71.2833   C85        C         17599          PC  \n2      0  STON/O2. 3101282   7.9250   NaN        S       3101282    STON/O2.  \n3      0            113803  53.1000  C123        S        113803        NONE  \n4      0            373450   8.0500   NaN        S        373450        NONE  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Ticket_Number</th>\n      <th>Ticket_Item</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund Mr Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>21171</td>\n      <td>A/5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings Mrs John Bradley Florence Briggs Thayer</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>17599</td>\n      <td>PC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen Miss Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>3101282</td>\n      <td>STON/O2.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle Mrs Jacques Heath Lily May Peel</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>113803</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen Mr William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>373450</td>\n      <td>NONE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's keep a list of the input features of the model. Notably, we don't want to train our model on the `PassengerID` and `Ticket` features because those columns likely have nothing to do with whether or not the passenger survived.","metadata":{}},{"cell_type":"code","source":"input_features = list(preprocessed_train_data.columns)\ninput_features.remove(\"Ticket\")\ninput_features.remove(\"PassengerId\")\ninput_features.remove(\"Survived\")\n\nprint(f\"Input features: {input_features}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-08T18:44:03.345974Z","iopub.execute_input":"2024-07-08T18:44:03.346402Z","iopub.status.idle":"2024-07-08T18:44:03.352537Z","shell.execute_reply.started":"2024-07-08T18:44:03.346367Z","shell.execute_reply":"2024-07-08T18:44:03.351344Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Input features: ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked', 'Ticket_Number', 'Ticket_Item']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Convert Pandas dataset to TensorFlow dataset","metadata":{}},{"cell_type":"code","source":"def tokenize_names(features, labels = None):\n    \"\"\"\n    Divide the names into tokens. TF-DF can consume text tokens\n    natively.\"\"\"\n    features[\"Name\"] = tf.strings.split(features[\"Name\"])\n    return features, labels\n\ntrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_train_data, label = \"Survived\").map(tokenize_names)\nserving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_test_data).map(tokenize_names)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T18:44:05.732306Z","iopub.execute_input":"2024-07-08T18:44:05.732748Z","iopub.status.idle":"2024-07-08T18:44:05.979191Z","shell.execute_reply.started":"2024-07-08T18:44:05.732717Z","shell.execute_reply":"2024-07-08T18:44:05.977783Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### Train model with default parameters\n#### Train model\nFirst, we are training a `GradientBoostedTreesModel` model with the default params.","metadata":{}},{"cell_type":"code","source":"model = tfdf.keras.GradientBoostedTreesModel(verbose = 0, \n                                            features = [tfdf.keras.FeatureUsage(name=n) for n in input_features],\n                                            exclude_non_specified_features=True,\n#                                             min_examples = 1,\n#                                             categorical_algorithm=\"RANDOM\",\n#                                             shrinkage=0.05,\n#                                             split_axis=\"SPARSE_OBLIQUE\",\n#                                             sparse_oblique_normalizations=\"MIN-MAX\",\n#                                             sparse_oblique_num_projections_exponent = 2.0,\n#                                             num_trees=2000,\n                                            random_seed = 1234, )\nmodel.fit(train_ds)\nself_evaluation = model.make_inspector().evaluation()\nprint(f\"Accuracy: {self_evaluation.accuracy} Loss: {self_evaluation.loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-08T18:52:30.338640Z","iopub.execute_input":"2024-07-08T18:52:30.339061Z","iopub.status.idle":"2024-07-08T18:52:43.164056Z","shell.execute_reply.started":"2024-07-08T18:52:30.339028Z","shell.execute_reply":"2024-07-08T18:52:43.162900Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"[WARNING 24-07-08 18:52:30.3742 UTC gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 24-07-08 18:52:30.3751 UTC gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 24-07-08 18:52:30.3751 UTC gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n[INFO 24-07-08 18:52:36.5681 UTC kernel.cc:1233] Loading model from path /tmp/tmp9h3pik8p/model/ with prefix 4c0fd90ea0f54c64\n[INFO 24-07-08 18:52:36.5745 UTC quick_scorer_extended.cc:903] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\n[INFO 24-07-08 18:52:36.5749 UTC abstract_model.cc:1344] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n[INFO 24-07-08 18:52:36.5749 UTC kernel.cc:1061] Use fast generic engine\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8260869383811951 Loss: 0.8608942627906799\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Train the model with improved default params\nNow you'll use specific parameters","metadata":{}},{"cell_type":"code","source":"model = tfdf.keras.GradientBoostedTreesModel(verbose = 0, \n                                            features = [tfdf.keras.FeatureUsage(name=n) for n in input_features],\n                                            exclude_non_specified_features=True,\n                                            min_examples = 1,\n                                            categorical_algorithm=\"RANDOM\",\n                                            shrinkage=0.05,\n                                            split_axis=\"SPARSE_OBLIQUE\",\n                                            sparse_oblique_normalization=\"MIN_MAX\",\n                                            sparse_oblique_num_projections_exponent = 2.0,\n                                            num_trees=2000,\n                                            random_seed = 1234, )\nmodel.fit(train_ds)\nself_evaluation = model.make_inspector().evaluation()\nprint(f\"Accuracy: {self_evaluation.accuracy} Loss: {self_evaluation.loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-08T18:54:41.380268Z","iopub.execute_input":"2024-07-08T18:54:41.380657Z","iopub.status.idle":"2024-07-08T18:54:42.718517Z","shell.execute_reply.started":"2024-07-08T18:54:41.380630Z","shell.execute_reply":"2024-07-08T18:54:42.717273Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"[WARNING 24-07-08 18:54:41.3960 UTC gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 24-07-08 18:54:41.3960 UTC gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 24-07-08 18:54:41.3960 UTC gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n[INFO 24-07-08 18:54:42.3359 UTC kernel.cc:1233] Loading model from path /tmp/tmp8vmifbjo/model/ with prefix cfdbb29b5e084be6\n[INFO 24-07-08 18:54:42.3448 UTC decision_forest.cc:660] Model loaded with 40 root(s), 2106 node(s), and 10 input feature(s).\n[INFO 24-07-08 18:54:42.3448 UTC abstract_model.cc:1344] Engine \"GradientBoostedTreesGeneric\" built\n[INFO 24-07-08 18:54:42.3448 UTC kernel.cc:1061] Use fast generic engine\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.782608687877655 Loss: 1.0586705207824707\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T18:55:35.167198Z","iopub.execute_input":"2024-07-08T18:55:35.167725Z","iopub.status.idle":"2024-07-08T18:55:35.187919Z","shell.execute_reply.started":"2024-07-08T18:55:35.167680Z","shell.execute_reply":"2024-07-08T18:55:35.186640Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Model: \"gradient_boosted_trees_model_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n=================================================================\nTotal params: 1 (1.00 Byte)\nTrainable params: 0 (0.00 Byte)\nNon-trainable params: 1 (1.00 Byte)\n_________________________________________________________________\nType: \"GRADIENT_BOOSTED_TREES\"\nTask: CLASSIFICATION\nLabel: \"__LABEL\"\n\nInput Features (11):\n\tAge\n\tCabin\n\tEmbarked\n\tFare\n\tName\n\tParch\n\tPclass\n\tSex\n\tSibSp\n\tTicket_Item\n\tTicket_Number\n\nNo weights\n\nVariable Importance: INV_MEAN_MIN_DEPTH:\n    1.           \"Sex\"  0.585997 ################\n    2.           \"Age\"  0.364636 #######\n    3.          \"Fare\"  0.266191 ###\n    4.          \"Name\"  0.207054 #\n    5.        \"Pclass\"  0.179191 \n    6. \"Ticket_Number\"  0.178806 \n    7.      \"Embarked\"  0.177803 \n    8.   \"Ticket_Item\"  0.177009 \n    9.         \"Parch\"  0.175276 \n   10.         \"SibSp\"  0.171694 \n\nVariable Importance: NUM_AS_ROOT:\n    1.  \"Sex\" 34.000000 ################\n    2. \"Name\"  6.000000 \n\nVariable Importance: NUM_NODES:\n    1.           \"Age\" 510.000000 ################\n    2.          \"Fare\" 298.000000 #########\n    3.          \"Name\" 60.000000 #\n    4.   \"Ticket_Item\" 47.000000 #\n    5.           \"Sex\" 40.000000 #\n    6.         \"Parch\" 22.000000 \n    7. \"Ticket_Number\" 20.000000 \n    8.      \"Embarked\" 15.000000 \n    9.        \"Pclass\" 15.000000 \n   10.         \"SibSp\"  6.000000 \n\nVariable Importance: SUM_SCORE:\n    1.           \"Sex\" 482.453470 ################\n    2.           \"Age\" 390.670218 ############\n    3.          \"Fare\" 321.170935 ##########\n    4.          \"Name\" 102.043860 ###\n    5.        \"Pclass\" 26.605919 \n    6.   \"Ticket_Item\" 22.954813 \n    7. \"Ticket_Number\" 17.413948 \n    8.      \"Embarked\"  8.969861 \n    9.         \"Parch\"  6.947528 \n   10.         \"SibSp\"  0.455899 \n\n\n\nLoss: BINOMIAL_LOG_LIKELIHOOD\nValidation loss value: 1.05867\nNumber of trees per iteration: 1\nNode format: NOT_SET\nNumber of trees: 40\nTotal number of nodes: 2106\n\nNumber of nodes by tree:\nCount: 40 Average: 52.65 StdDev: 4.2869\nMin: 41 Max: 61 Ignored: 0\n----------------------------------------------\n[ 41, 42)  2   5.00%   5.00% ##\n[ 42, 43)  0   0.00%   5.00%\n[ 43, 44)  0   0.00%   5.00%\n[ 44, 45)  0   0.00%   5.00%\n[ 45, 46)  0   0.00%   5.00%\n[ 46, 47)  0   0.00%   5.00%\n[ 47, 48)  4  10.00%  15.00% ####\n[ 48, 49)  0   0.00%  15.00%\n[ 49, 50)  3   7.50%  22.50% ###\n[ 50, 51)  0   0.00%  22.50%\n[ 51, 52)  4  10.00%  32.50% ####\n[ 52, 53)  0   0.00%  32.50%\n[ 53, 54) 11  27.50%  60.00% ##########\n[ 54, 55)  0   0.00%  60.00%\n[ 55, 56) 10  25.00%  85.00% #########\n[ 56, 57)  0   0.00%  85.00%\n[ 57, 58)  2   5.00%  90.00% ##\n[ 58, 59)  0   0.00%  90.00%\n[ 59, 60)  3   7.50%  97.50% ###\n[ 60, 61]  1   2.50% 100.00% #\n\nDepth by leafs:\nCount: 1073 Average: 4.84623 StdDev: 0.454477\nMin: 2 Max: 5 Ignored: 0\n----------------------------------------------\n[ 2, 3)   1   0.09%   0.09%\n[ 3, 4)  38   3.54%   3.63%\n[ 4, 5)  86   8.01%  11.65% #\n[ 5, 5] 948  88.35% 100.00% ##########\n\nNumber of training obs by leaf:\nCount: 1073 Average: 29.7856 StdDev: 71.8675\nMin: 1 Max: 458 Ignored: 0\n----------------------------------------------\n[   1,  23) 846  78.84%  78.84% ##########\n[  23,  46)  62   5.78%  84.62% #\n[  46,  69)  48   4.47%  89.10% #\n[  69,  92)  21   1.96%  91.05%\n[  92, 115)  10   0.93%  91.99%\n[ 115, 138)  15   1.40%  93.38%\n[ 138, 161)  23   2.14%  95.53%\n[ 161, 184)   6   0.56%  96.09%\n[ 184, 207)   3   0.28%  96.37%\n[ 207, 230)   4   0.37%  96.74%\n[ 230, 252)   1   0.09%  96.83%\n[ 252, 275)   1   0.09%  96.92%\n[ 275, 298)   2   0.19%  97.11%\n[ 298, 321)   2   0.19%  97.30%\n[ 321, 344)   0   0.00%  97.30%\n[ 344, 367)   9   0.84%  98.14%\n[ 367, 390)   6   0.56%  98.70%\n[ 390, 413)   9   0.84%  99.53%\n[ 413, 436)   4   0.37%  99.91%\n[ 436, 458]   1   0.09% 100.00%\n\nAttribute in nodes:\n\t510 : Age [NUMERICAL]\n\t298 : Fare [NUMERICAL]\n\t60 : Name [CATEGORICAL_SET]\n\t47 : Ticket_Item [CATEGORICAL]\n\t40 : Sex [CATEGORICAL]\n\t22 : Parch [NUMERICAL]\n\t20 : Ticket_Number [CATEGORICAL]\n\t15 : Pclass [NUMERICAL]\n\t15 : Embarked [CATEGORICAL]\n\t6 : SibSp [NUMERICAL]\n\nAttribute in nodes with depth <= 0:\n\t34 : Sex [CATEGORICAL]\n\t6 : Name [CATEGORICAL_SET]\n\nAttribute in nodes with depth <= 1:\n\t48 : Age [NUMERICAL]\n\t34 : Sex [CATEGORICAL]\n\t25 : Fare [NUMERICAL]\n\t6 : Name [CATEGORICAL_SET]\n\t5 : Pclass [NUMERICAL]\n\t2 : Ticket_Number [CATEGORICAL]\n\nAttribute in nodes with depth <= 2:\n\t121 : Age [NUMERICAL]\n\t74 : Fare [NUMERICAL]\n\t34 : Sex [CATEGORICAL]\n\t19 : Name [CATEGORICAL_SET]\n\t8 : Ticket_Number [CATEGORICAL]\n\t8 : Embarked [CATEGORICAL]\n\t6 : Pclass [NUMERICAL]\n\t6 : Parch [NUMERICAL]\n\t3 : Ticket_Item [CATEGORICAL]\n\nAttribute in nodes with depth <= 3:\n\t261 : Age [NUMERICAL]\n\t164 : Fare [NUMERICAL]\n\t36 : Sex [CATEGORICAL]\n\t35 : Name [CATEGORICAL_SET]\n\t16 : Ticket_Item [CATEGORICAL]\n\t13 : Ticket_Number [CATEGORICAL]\n\t12 : Embarked [CATEGORICAL]\n\t11 : Parch [NUMERICAL]\n\t9 : Pclass [NUMERICAL]\n\t2 : SibSp [NUMERICAL]\n\nAttribute in nodes with depth <= 5:\n\t510 : Age [NUMERICAL]\n\t298 : Fare [NUMERICAL]\n\t60 : Name [CATEGORICAL_SET]\n\t47 : Ticket_Item [CATEGORICAL]\n\t40 : Sex [CATEGORICAL]\n\t22 : Parch [NUMERICAL]\n\t20 : Ticket_Number [CATEGORICAL]\n\t15 : Pclass [NUMERICAL]\n\t15 : Embarked [CATEGORICAL]\n\t6 : SibSp [NUMERICAL]\n\nCondition type in nodes:\n\t851 : ObliqueCondition\n\t135 : ContainsBitmapCondition\n\t47 : ContainsCondition\nCondition type in nodes with depth <= 0:\n\t38 : ContainsBitmapCondition\n\t2 : ContainsCondition\nCondition type in nodes with depth <= 1:\n\t78 : ObliqueCondition\n\t40 : ContainsBitmapCondition\n\t2 : ContainsCondition\nCondition type in nodes with depth <= 2:\n\t207 : ObliqueCondition\n\t58 : ContainsBitmapCondition\n\t14 : ContainsCondition\nCondition type in nodes with depth <= 3:\n\t447 : ObliqueCondition\n\t83 : ContainsBitmapCondition\n\t29 : ContainsCondition\nCondition type in nodes with depth <= 5:\n\t851 : ObliqueCondition\n\t135 : ContainsBitmapCondition\n\t47 : ContainsCondition\n\nTraining logs:\nNumber of iteration to final model: 40\n\tIter:1 train-loss:1.264594 valid-loss:1.360749  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:2 train-loss:1.210623 valid-loss:1.320363  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:3 train-loss:1.160657 valid-loss:1.281972  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:4 train-loss:1.116982 valid-loss:1.250548  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:5 train-loss:1.075170 valid-loss:1.221467  train-accuracy:0.807259 valid-accuracy:0.760870\n\tIter:6 train-loss:1.035656 valid-loss:1.199482  train-accuracy:0.822278 valid-accuracy:0.760870\n\tIter:16 train-loss:0.787670 valid-loss:1.088161  train-accuracy:0.903630 valid-accuracy:0.771739\n\tIter:26 train-loss:0.647960 valid-loss:1.065191  train-accuracy:0.922403 valid-accuracy:0.782609\n\tIter:36 train-loss:0.557737 valid-loss:1.071260  train-accuracy:0.922403 valid-accuracy:0.782609\n\tIter:46 train-loss:0.494259 valid-loss:1.063639  train-accuracy:0.927409 valid-accuracy:0.771739\n\tIter:56 train-loss:0.443537 valid-loss:1.070069  train-accuracy:0.939925 valid-accuracy:0.760870\n\tIter:66 train-loss:0.404514 valid-loss:1.081874  train-accuracy:0.949937 valid-accuracy:0.760870\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Make Predictions","metadata":{}},{"cell_type":"code","source":"def prediction_to_kaggle_format(model, threshold=0.5):\n    proba_survive = model.predict(serving_ds, verbose =0)[:,0]\n    return pd.DataFrame({\n        \"PassengerId\": test_data[\"PassengerId\"],\n        \"Survived\": (proba_survive >= threshold).astype(int)\n    })\ndef make_submission(kaggle_preds):\n    path = \"/kaggle/working/submission.csv\"\n    kaggle_predictions.to_csv(path, index=False)\n    print(f\"Submission exported to {path}\")\n    \nkaggle_predictions = prediction_to_kaggle_format(model)\nmake_submission(kaggle_predictions)\n!head /kaggle/working/submission.csv","metadata":{"execution":{"iopub.status.busy":"2024-07-08T19:00:25.487312Z","iopub.execute_input":"2024-07-08T19:00:25.487765Z","iopub.status.idle":"2024-07-08T19:00:26.740441Z","shell.execute_reply.started":"2024-07-08T19:00:25.487734Z","shell.execute_reply":"2024-07-08T19:00:26.738871Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Submission exported to /kaggle/working/submission.csv\nPassengerId,Survived\n892,0\n893,0\n894,0\n895,0\n896,0\n897,0\n898,0\n899,0\n900,1\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}