{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a07bb7d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-08T19:04:07.698555Z",
     "iopub.status.busy": "2024-07-08T19:04:07.698150Z",
     "iopub.status.idle": "2024-07-08T19:04:08.692155Z",
     "shell.execute_reply": "2024-07-08T19:04:08.690800Z"
    },
    "papermill": {
     "duration": 1.003292,
     "end_time": "2024-07-08T19:04:08.694796",
     "exception": false,
     "start_time": "2024-07-08T19:04:07.691504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ad97c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T19:04:08.706528Z",
     "iopub.status.busy": "2024-07-08T19:04:08.705992Z",
     "iopub.status.idle": "2024-07-08T19:04:08.736967Z",
     "shell.execute_reply": "2024-07-08T19:04:08.735846Z"
    },
    "papermill": {
     "duration": 0.039789,
     "end_time": "2024-07-08T19:04:08.739761",
     "exception": false,
     "start_time": "2024-07-08T19:04:08.699972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "480abfe2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T19:04:08.751278Z",
     "iopub.status.busy": "2024-07-08T19:04:08.750318Z",
     "iopub.status.idle": "2024-07-08T19:04:08.781065Z",
     "shell.execute_reply": "2024-07-08T19:04:08.779854Z"
    },
    "papermill": {
     "duration": 0.039336,
     "end_time": "2024-07-08T19:04:08.783824",
     "exception": false,
     "start_time": "2024-07-08T19:04:08.744488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "182047f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T19:04:08.795511Z",
     "iopub.status.busy": "2024-07-08T19:04:08.795102Z",
     "iopub.status.idle": "2024-07-08T19:04:25.316690Z",
     "shell.execute_reply": "2024-07-08T19:04:25.315230Z"
    },
    "papermill": {
     "duration": 16.530276,
     "end_time": "2024-07-08T19:04:25.319146",
     "exception": false,
     "start_time": "2024-07-08T19:04:08.788870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 19:04:11.298811: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-08 19:04:11.298981: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-08 19:04:11.489727: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found TF-DF 1.8.1\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "print(f\"Found TF-DF {tfdf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c435675f",
   "metadata": {
    "papermill": {
     "duration": 0.00469,
     "end_time": "2024-07-08T19:04:25.329049",
     "exception": false,
     "start_time": "2024-07-08T19:04:25.324359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prepare Dataset\n",
    "We will apply the following transformations on the dataset.\n",
    "* Tokenize the names. For example, \"Brauind, Mr. Owen Harris\" will become [\"Braund\", \"Mr.\", \"Owen\", \"Harris\"].\n",
    "* Extract any prefix in the ticket. For example, ticket \"STON/O2.3101282\" will become \"STON/O2.\" and 3101282."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2394d5eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T19:04:25.341434Z",
     "iopub.status.busy": "2024-07-08T19:04:25.340681Z",
     "iopub.status.idle": "2024-07-08T19:04:25.371944Z",
     "shell.execute_reply": "2024-07-08T19:04:25.370639Z"
    },
    "papermill": {
     "duration": 0.040525,
     "end_time": "2024-07-08T19:04:25.374603",
     "exception": false,
     "start_time": "2024-07-08T19:04:25.334078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Ticket_Number</th>\n",
       "      <th>Ticket_Item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund Mr Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21171</td>\n",
       "      <td>A/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings Mrs John Bradley Florence Briggs Thayer</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>17599</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen Miss Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>3101282</td>\n",
       "      <td>STON/O2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle Mrs Jacques Heath Lily May Peel</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>113803</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen Mr William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>373450</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                              Name     Sex   Age  SibSp  \\\n",
       "0                            Braund Mr Owen Harris    male  22.0      1   \n",
       "1  Cumings Mrs John Bradley Florence Briggs Thayer  female  38.0      1   \n",
       "2                             Heikkinen Miss Laina  female  26.0      0   \n",
       "3         Futrelle Mrs Jacques Heath Lily May Peel  female  35.0      1   \n",
       "4                           Allen Mr William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked Ticket_Number Ticket_Item  \n",
       "0      0         A/5 21171   7.2500   NaN        S         21171         A/5  \n",
       "1      0          PC 17599  71.2833   C85        C         17599          PC  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S       3101282    STON/O2.  \n",
       "3      0            113803  53.1000  C123        S        113803        NONE  \n",
       "4      0            373450   8.0500   NaN        S        373450        NONE  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    def normalize_name(x):\n",
    "        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n",
    "\n",
    "    def ticket_number(x):\n",
    "        return x.split(\" \")[-1]\n",
    "    \n",
    "    def ticket_item(x):\n",
    "        items = x.split(\" \")\n",
    "        if len(items) == 1:\n",
    "            return \"NONE\"\n",
    "        return \"_\".join(items[0:-1])\n",
    "    \n",
    "    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n",
    "    df[\"Ticket_Number\"] = df[\"Ticket\"].apply(ticket_number)\n",
    "    df[\"Ticket_Item\"] = df[\"Ticket\"].apply(ticket_item)\n",
    "    return df\n",
    "\n",
    "preprocessed_train_data = preprocess(train_data)\n",
    "preprocessed_test_data = preprocess(test_data)\n",
    "\n",
    "preprocessed_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a608aaa3",
   "metadata": {
    "papermill": {
     "duration": 0.005118,
     "end_time": "2024-07-08T19:04:25.385191",
     "exception": false,
     "start_time": "2024-07-08T19:04:25.380073",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's keep a list of the input features of the model. Notably, we don't want to train our model on the `PassengerID` and `Ticket` features because those columns likely have nothing to do with whether or not the passenger survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02f7f253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T19:04:25.397964Z",
     "iopub.status.busy": "2024-07-08T19:04:25.397562Z",
     "iopub.status.idle": "2024-07-08T19:04:25.404001Z",
     "shell.execute_reply": "2024-07-08T19:04:25.402921Z"
    },
    "papermill": {
     "duration": 0.015737,
     "end_time": "2024-07-08T19:04:25.406501",
     "exception": false,
     "start_time": "2024-07-08T19:04:25.390764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features: ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked', 'Ticket_Number', 'Ticket_Item']\n"
     ]
    }
   ],
   "source": [
    "input_features = list(preprocessed_train_data.columns)\n",
    "input_features.remove(\"Ticket\")\n",
    "input_features.remove(\"PassengerId\")\n",
    "input_features.remove(\"Survived\")\n",
    "\n",
    "print(f\"Input features: {input_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe5433",
   "metadata": {
    "papermill": {
     "duration": 0.005291,
     "end_time": "2024-07-08T19:04:25.417321",
     "exception": false,
     "start_time": "2024-07-08T19:04:25.412030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Convert Pandas dataset to TensorFlow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cee54509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T19:04:25.430334Z",
     "iopub.status.busy": "2024-07-08T19:04:25.429938Z",
     "iopub.status.idle": "2024-07-08T19:04:25.902957Z",
     "shell.execute_reply": "2024-07-08T19:04:25.901959Z"
    },
    "papermill": {
     "duration": 0.483054,
     "end_time": "2024-07-08T19:04:25.906207",
     "exception": false,
     "start_time": "2024-07-08T19:04:25.423153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_names(features, labels = None):\n",
    "    \"\"\"\n",
    "    Divide the names into tokens. TF-DF can consume text tokens\n",
    "    natively.\"\"\"\n",
    "    features[\"Name\"] = tf.strings.split(features[\"Name\"])\n",
    "    return features, labels\n",
    "\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_train_data, label = \"Survived\").map(tokenize_names)\n",
    "serving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_test_data).map(tokenize_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb157ae1",
   "metadata": {
    "papermill": {
     "duration": 0.00527,
     "end_time": "2024-07-08T19:04:25.917190",
     "exception": false,
     "start_time": "2024-07-08T19:04:25.911920",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train model with default parameters\n",
    "#### Train model\n",
    "First, we are training a `GradientBoostedTreesModel` model with the default params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36ed0159",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T19:04:25.930145Z",
     "iopub.status.busy": "2024-07-08T19:04:25.929397Z",
     "iopub.status.idle": "2024-07-08T19:04:38.310109Z",
     "shell.execute_reply": "2024-07-08T19:04:38.308615Z"
    },
    "papermill": {
     "duration": 12.389991,
     "end_time": "2024-07-08T19:04:38.312649",
     "exception": false,
     "start_time": "2024-07-08T19:04:25.922658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 24-07-08 19:04:25.9710 UTC gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-07-08 19:04:25.9719 UTC gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-07-08 19:04:25.9719 UTC gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 24-07-08 19:04:31.7273 UTC kernel.cc:1233] Loading model from path /tmp/tmpf5fr6zoq/model/ with prefix ddbb1f9b52d147bf\n",
      "[INFO 24-07-08 19:04:31.7341 UTC quick_scorer_extended.cc:903] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\n",
      "[INFO 24-07-08 19:04:31.7346 UTC abstract_model.cc:1344] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "[INFO 24-07-08 19:04:31.7347 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8260869383811951 Loss: 0.8608942627906799\n"
     ]
    }
   ],
   "source": [
    "model = tfdf.keras.GradientBoostedTreesModel(verbose = 0, \n",
    "                                            features = [tfdf.keras.FeatureUsage(name=n) for n in input_features],\n",
    "                                            exclude_non_specified_features=True,\n",
    "#                                             min_examples = 1,\n",
    "#                                             categorical_algorithm=\"RANDOM\",\n",
    "#                                             shrinkage=0.05,\n",
    "#                                             split_axis=\"SPARSE_OBLIQUE\",\n",
    "#                                             sparse_oblique_normalizations=\"MIN-MAX\",\n",
    "#                                             sparse_oblique_num_projections_exponent = 2.0,\n",
    "#                                             num_trees=2000,\n",
    "                                            random_seed = 1234, )\n",
    "model.fit(train_ds)\n",
    "self_evaluation = model.make_inspector().evaluation()\n",
    "print(f\"Accuracy: {self_evaluation.accuracy} Loss: {self_evaluation.loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8294c3",
   "metadata": {
    "papermill": {
     "duration": 0.005383,
     "end_time": "2024-07-08T19:04:38.323940",
     "exception": false,
     "start_time": "2024-07-08T19:04:38.318557",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train the model with improved default params\n",
    "Now you'll use specific parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0bf3da1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T19:04:38.337094Z",
     "iopub.status.busy": "2024-07-08T19:04:38.336706Z",
     "iopub.status.idle": "2024-07-08T19:04:39.633756Z",
     "shell.execute_reply": "2024-07-08T19:04:39.632063Z"
    },
    "papermill": {
     "duration": 1.306734,
     "end_time": "2024-07-08T19:04:39.636323",
     "exception": false,
     "start_time": "2024-07-08T19:04:38.329589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING 24-07-08 19:04:38.3506 UTC gradient_boosted_trees.cc:1886] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-07-08 19:04:38.3507 UTC gradient_boosted_trees.cc:1897] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "[WARNING 24-07-08 19:04:38.3507 UTC gradient_boosted_trees.cc:1911] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "[INFO 24-07-08 19:04:39.2811 UTC kernel.cc:1233] Loading model from path /tmp/tmp8dwvmbnl/model/ with prefix 8871b5eb9b984596\n",
      "[INFO 24-07-08 19:04:39.2893 UTC decision_forest.cc:660] Model loaded with 40 root(s), 2106 node(s), and 10 input feature(s).\n",
      "[INFO 24-07-08 19:04:39.2893 UTC kernel.cc:1061] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.782608687877655 Loss: 1.0586705207824707\n"
     ]
    }
   ],
   "source": [
    "model = tfdf.keras.GradientBoostedTreesModel(verbose = 0, \n",
    "                                            features = [tfdf.keras.FeatureUsage(name=n) for n in input_features],\n",
    "                                            exclude_non_specified_features=True,\n",
    "                                            min_examples = 1,\n",
    "                                            categorical_algorithm=\"RANDOM\",\n",
    "                                            shrinkage=0.05,\n",
    "                                            split_axis=\"SPARSE_OBLIQUE\",\n",
    "                                            sparse_oblique_normalization=\"MIN_MAX\",\n",
    "                                            sparse_oblique_num_projections_exponent = 2.0,\n",
    "                                            num_trees=2000,\n",
    "                                            random_seed = 1234, )\n",
    "model.fit(train_ds)\n",
    "self_evaluation = model.make_inspector().evaluation()\n",
    "print(f\"Accuracy: {self_evaluation.accuracy} Loss: {self_evaluation.loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b90088c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T19:04:39.651691Z",
     "iopub.status.busy": "2024-07-08T19:04:39.650591Z",
     "iopub.status.idle": "2024-07-08T19:04:39.667739Z",
     "shell.execute_reply": "2024-07-08T19:04:39.666601Z"
    },
    "papermill": {
     "duration": 0.030776,
     "end_time": "2024-07-08T19:04:39.673625",
     "exception": false,
     "start_time": "2024-07-08T19:04:39.642849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gradient_boosted_trees_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 1 (1.00 Byte)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 1 (1.00 Byte)\n",
      "_________________________________________________________________\n",
      "Type: \"GRADIENT_BOOSTED_TREES\"\n",
      "Task: CLASSIFICATION\n",
      "Label: \"__LABEL\"\n",
      "\n",
      "Input Features (11):\n",
      "\tAge\n",
      "\tCabin\n",
      "\tEmbarked\n",
      "\tFare\n",
      "\tName\n",
      "\tParch\n",
      "\tPclass\n",
      "\tSex\n",
      "\tSibSp\n",
      "\tTicket_Item\n",
      "\tTicket_Number\n",
      "\n",
      "No weights\n",
      "\n",
      "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
      "    1.           \"Sex\"  0.585997 ################\n",
      "    2.           \"Age\"  0.364636 #######\n",
      "    3.          \"Fare\"  0.266191 ###\n",
      "    4.          \"Name\"  0.207054 #\n",
      "    5.        \"Pclass\"  0.179191 \n",
      "    6. \"Ticket_Number\"  0.178806 \n",
      "    7.      \"Embarked\"  0.177803 \n",
      "    8.   \"Ticket_Item\"  0.177009 \n",
      "    9.         \"Parch\"  0.175276 \n",
      "   10.         \"SibSp\"  0.171694 \n",
      "\n",
      "Variable Importance: NUM_AS_ROOT:\n",
      "    1.  \"Sex\" 34.000000 ################\n",
      "    2. \"Name\"  6.000000 \n",
      "\n",
      "Variable Importance: NUM_NODES:\n",
      "    1.           \"Age\" 510.000000 ################\n",
      "    2.          \"Fare\" 298.000000 #########\n",
      "    3.          \"Name\" 60.000000 #\n",
      "    4.   \"Ticket_Item\" 47.000000 #\n",
      "    5.           \"Sex\" 40.000000 #\n",
      "    6.         \"Parch\" 22.000000 \n",
      "    7. \"Ticket_Number\" 20.000000 \n",
      "    8.      \"Embarked\" 15.000000 \n",
      "    9.        \"Pclass\" 15.000000 \n",
      "   10.         \"SibSp\"  6.000000 \n",
      "\n",
      "Variable Importance: SUM_SCORE:\n",
      "    1.           \"Sex\" 482.453470 ################\n",
      "    2.           \"Age\" 390.670218 ############\n",
      "    3.          \"Fare\" 321.170935 ##########\n",
      "    4.          \"Name\" 102.043860 ###\n",
      "    5.        \"Pclass\" 26.605919 \n",
      "    6.   \"Ticket_Item\" 22.954813 \n",
      "    7. \"Ticket_Number\" 17.413948 \n",
      "    8.      \"Embarked\"  8.969861 \n",
      "    9.         \"Parch\"  6.947528 \n",
      "   10.         \"SibSp\"  0.455899 \n",
      "\n",
      "\n",
      "\n",
      "Loss: BINOMIAL_LOG_LIKELIHOOD\n",
      "Validation loss value: 1.05867\n",
      "Number of trees per iteration: 1\n",
      "Node format: NOT_SET\n",
      "Number of trees: 40\n",
      "Total number of nodes: 2106\n",
      "\n",
      "Number of nodes by tree:\n",
      "Count: 40 Average: 52.65 StdDev: 4.2869\n",
      "Min: 41 Max: 61 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 41, 42)  2   5.00%   5.00% ##\n",
      "[ 42, 43)  0   0.00%   5.00%\n",
      "[ 43, 44)  0   0.00%   5.00%\n",
      "[ 44, 45)  0   0.00%   5.00%\n",
      "[ 45, 46)  0   0.00%   5.00%\n",
      "[ 46, 47)  0   0.00%   5.00%\n",
      "[ 47, 48)  4  10.00%  15.00% ####\n",
      "[ 48, 49)  0   0.00%  15.00%\n",
      "[ 49, 50)  3   7.50%  22.50% ###\n",
      "[ 50, 51)  0   0.00%  22.50%\n",
      "[ 51, 52)  4  10.00%  32.50% ####\n",
      "[ 52, 53)  0   0.00%  32.50%\n",
      "[ 53, 54) 11  27.50%  60.00% ##########\n",
      "[ 54, 55)  0   0.00%  60.00%\n",
      "[ 55, 56) 10  25.00%  85.00% #########\n",
      "[ 56, 57)  0   0.00%  85.00%\n",
      "[ 57, 58)  2   5.00%  90.00% ##\n",
      "[ 58, 59)  0   0.00%  90.00%\n",
      "[ 59, 60)  3   7.50%  97.50% ###\n",
      "[ 60, 61]  1   2.50% 100.00% #\n",
      "\n",
      "Depth by leafs:\n",
      "Count: 1073 Average: 4.84623 StdDev: 0.454477\n",
      "Min: 2 Max: 5 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 2, 3)   1   0.09%   0.09%\n",
      "[ 3, 4)  38   3.54%   3.63%\n",
      "[ 4, 5)  86   8.01%  11.65% #\n",
      "[ 5, 5] 948  88.35% 100.00% ##########\n",
      "\n",
      "Number of training obs by leaf:\n",
      "Count: 1073 Average: 29.7856 StdDev: 71.8675\n",
      "Min: 1 Max: 458 Ignored: 0\n",
      "----------------------------------------------\n",
      "[   1,  23) 846  78.84%  78.84% ##########\n",
      "[  23,  46)  62   5.78%  84.62% #\n",
      "[  46,  69)  48   4.47%  89.10% #\n",
      "[  69,  92)  21   1.96%  91.05%\n",
      "[  92, 115)  10   0.93%  91.99%\n",
      "[ 115, 138)  15   1.40%  93.38%\n",
      "[ 138, 161)  23   2.14%  95.53%\n",
      "[ 161, 184)   6   0.56%  96.09%\n",
      "[ 184, 207)   3   0.28%  96.37%\n",
      "[ 207, 230)   4   0.37%  96.74%\n",
      "[ 230, 252)   1   0.09%  96.83%\n",
      "[ 252, 275)   1   0.09%  96.92%\n",
      "[ 275, 298)   2   0.19%  97.11%\n",
      "[ 298, 321)   2   0.19%  97.30%\n",
      "[ 321, 344)   0   0.00%  97.30%\n",
      "[ 344, 367)   9   0.84%  98.14%\n",
      "[ 367, 390)   6   0.56%  98.70%\n",
      "[ 390, 413)   9   0.84%  99.53%\n",
      "[ 413, 436)   4   0.37%  99.91%\n",
      "[ 436, 458]   1   0.09% 100.00%\n",
      "\n",
      "Attribute in nodes:\n",
      "\t510 : Age [NUMERICAL]\n",
      "\t298 : Fare [NUMERICAL]\n",
      "\t60 : Name [CATEGORICAL_SET]\n",
      "\t47 : Ticket_Item [CATEGORICAL]\n",
      "\t40 : Sex [CATEGORICAL]\n",
      "\t22 : Parch [NUMERICAL]\n",
      "\t20 : Ticket_Number [CATEGORICAL]\n",
      "\t15 : Pclass [NUMERICAL]\n",
      "\t15 : Embarked [CATEGORICAL]\n",
      "\t6 : SibSp [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 0:\n",
      "\t34 : Sex [CATEGORICAL]\n",
      "\t6 : Name [CATEGORICAL_SET]\n",
      "\n",
      "Attribute in nodes with depth <= 1:\n",
      "\t48 : Age [NUMERICAL]\n",
      "\t34 : Sex [CATEGORICAL]\n",
      "\t25 : Fare [NUMERICAL]\n",
      "\t6 : Name [CATEGORICAL_SET]\n",
      "\t5 : Pclass [NUMERICAL]\n",
      "\t2 : Ticket_Number [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 2:\n",
      "\t121 : Age [NUMERICAL]\n",
      "\t74 : Fare [NUMERICAL]\n",
      "\t34 : Sex [CATEGORICAL]\n",
      "\t19 : Name [CATEGORICAL_SET]\n",
      "\t8 : Ticket_Number [CATEGORICAL]\n",
      "\t8 : Embarked [CATEGORICAL]\n",
      "\t6 : Pclass [NUMERICAL]\n",
      "\t6 : Parch [NUMERICAL]\n",
      "\t3 : Ticket_Item [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 3:\n",
      "\t261 : Age [NUMERICAL]\n",
      "\t164 : Fare [NUMERICAL]\n",
      "\t36 : Sex [CATEGORICAL]\n",
      "\t35 : Name [CATEGORICAL_SET]\n",
      "\t16 : Ticket_Item [CATEGORICAL]\n",
      "\t13 : Ticket_Number [CATEGORICAL]\n",
      "\t12 : Embarked [CATEGORICAL]\n",
      "\t11 : Parch [NUMERICAL]\n",
      "\t9 : Pclass [NUMERICAL]\n",
      "\t2 : SibSp [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 5:\n",
      "\t510 : Age [NUMERICAL]\n",
      "\t298 : Fare [NUMERICAL]\n",
      "\t60 : Name [CATEGORICAL_SET]\n",
      "\t47 : Ticket_Item [CATEGORICAL]\n",
      "\t40 : Sex [CATEGORICAL]\n",
      "\t22 : Parch [NUMERICAL]\n",
      "\t20 : Ticket_Number [CATEGORICAL]\n",
      "\t15 : Pclass [NUMERICAL]\n",
      "\t15 : Embarked [CATEGORICAL]\n",
      "\t6 : SibSp [NUMERICAL]\n",
      "\n",
      "Condition type in nodes:\n",
      "\t851 : ObliqueCondition\n",
      "\t135 : ContainsBitmapCondition\n",
      "\t47 : ContainsCondition\n",
      "Condition type in nodes with depth <= 0:\n",
      "\t38 : ContainsBitmapCondition\n",
      "\t2 : ContainsCondition\n",
      "Condition type in nodes with depth <= 1:\n",
      "\t78 : ObliqueCondition\n",
      "\t40 : ContainsBitmapCondition\n",
      "\t2 : ContainsCondition\n",
      "Condition type in nodes with depth <= 2:\n",
      "\t207 : ObliqueCondition\n",
      "\t58 : ContainsBitmapCondition\n",
      "\t14 : ContainsCondition\n",
      "Condition type in nodes with depth <= 3:\n",
      "\t447 : ObliqueCondition\n",
      "\t83 : ContainsBitmapCondition\n",
      "\t29 : ContainsCondition\n",
      "Condition type in nodes with depth <= 5:\n",
      "\t851 : ObliqueCondition\n",
      "\t135 : ContainsBitmapCondition\n",
      "\t47 : ContainsCondition\n",
      "\n",
      "Training logs:\n",
      "Number of iteration to final model: 40\n",
      "\tIter:1 train-loss:1.264594 valid-loss:1.360749  train-accuracy:0.624531 valid-accuracy:0.543478\n",
      "\tIter:2 train-loss:1.210623 valid-loss:1.320363  train-accuracy:0.624531 valid-accuracy:0.543478\n",
      "\tIter:3 train-loss:1.160657 valid-loss:1.281972  train-accuracy:0.624531 valid-accuracy:0.543478\n",
      "\tIter:4 train-loss:1.116982 valid-loss:1.250548  train-accuracy:0.624531 valid-accuracy:0.543478\n",
      "\tIter:5 train-loss:1.075170 valid-loss:1.221467  train-accuracy:0.807259 valid-accuracy:0.760870\n",
      "\tIter:6 train-loss:1.035656 valid-loss:1.199482  train-accuracy:0.822278 valid-accuracy:0.760870\n",
      "\tIter:16 train-loss:0.787670 valid-loss:1.088161  train-accuracy:0.903630 valid-accuracy:0.771739\n",
      "\tIter:26 train-loss:0.647960 valid-loss:1.065191  train-accuracy:0.922403 valid-accuracy:0.782609\n",
      "\tIter:36 train-loss:0.557737 valid-loss:1.071260  train-accuracy:0.922403 valid-accuracy:0.782609\n",
      "\tIter:46 train-loss:0.494259 valid-loss:1.063639  train-accuracy:0.927409 valid-accuracy:0.771739\n",
      "\tIter:56 train-loss:0.443537 valid-loss:1.070069  train-accuracy:0.939925 valid-accuracy:0.760870\n",
      "\tIter:66 train-loss:0.404514 valid-loss:1.081874  train-accuracy:0.949937 valid-accuracy:0.760870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a39ea4",
   "metadata": {
    "papermill": {
     "duration": 0.006262,
     "end_time": "2024-07-08T19:04:39.686969",
     "exception": false,
     "start_time": "2024-07-08T19:04:39.680707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "078a1565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T19:04:39.702054Z",
     "iopub.status.busy": "2024-07-08T19:04:39.701624Z",
     "iopub.status.idle": "2024-07-08T19:04:40.940289Z",
     "shell.execute_reply": "2024-07-08T19:04:40.938963Z"
    },
    "papermill": {
     "duration": 1.24959,
     "end_time": "2024-07-08T19:04:40.943286",
     "exception": false,
     "start_time": "2024-07-08T19:04:39.693696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission exported to /kaggle/working/submission.csv\n",
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,0\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,0\r\n",
      "897,0\r\n",
      "898,0\r\n",
      "899,0\r\n",
      "900,1\r\n"
     ]
    }
   ],
   "source": [
    "def prediction_to_kaggle_format(model, threshold=0.5):\n",
    "    proba_survive = model.predict(serving_ds, verbose =0)[:,0]\n",
    "    return pd.DataFrame({\n",
    "        \"PassengerId\": test_data[\"PassengerId\"],\n",
    "        \"Survived\": (proba_survive >= threshold).astype(int)\n",
    "    })\n",
    "def make_submission(kaggle_preds):\n",
    "    path = \"/kaggle/working/submission.csv\"\n",
    "    kaggle_predictions.to_csv(path, index=False)\n",
    "    print(f\"Submission exported to {path}\")\n",
    "    \n",
    "kaggle_predictions = prediction_to_kaggle_format(model)\n",
    "make_submission(kaggle_predictions)\n",
    "!head /kaggle/working/submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1710a34b",
   "metadata": {
    "papermill": {
     "duration": 0.006851,
     "end_time": "2024-07-08T19:04:40.957938",
     "exception": false,
     "start_time": "2024-07-08T19:04:40.951087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38.050342,
   "end_time": "2024-07-08T19:04:42.691414",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-08T19:04:04.641072",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
